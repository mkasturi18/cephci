# Objective: Testing mutlisite upgrade from RHCS 4 GA to RHCS 4 latest build.
# rgw configured with ssl frontend
---
tests:

  - test:
      abort-on-fail: true
      desc: install ceph pre requisites
      module: install_prereq.py
      name: install vm pre-requsites

  - test:
      abort-on-fail: true
      clusters:
        ceph-rgw1:
          config:
            use_cdn: true
            build: "4.x"
            ansi_config:
              ceph_origin: repository
              ceph_repository: rhcs
              ceph_repository_type: cdn
              ceph_rhcs_version: 4
              osd_scenario: lvm
              osd_auto_discovery: false
              radosgw_frontend_ssl_certificate: "/etc/ceph/server.pem"
              radosgw_frontend_port: 443
              copy_admin_key: true
              dashboard_enabled: false
              rgw_multisite: true
              rgw_zone: US_EAST
              rgw_zonegroup: US
              rgw_realm: USA
              rgw_zonemaster: true
              rgw_zonesecondary: false
              rgw_zonegroupmaster: true
              rgw_zone_user: synchronization-user
              rgw_zone_user_display_name: "Synchronization User"
              rgw_multisite_proto: "https"
              system_access_key: 86nBoQOGpQgKxh4BLMyq
              system_secret_key: NTnkbmkMuzPjgwsBpJ6o
        ceph-rgw2:
          config:
            use_cdn: true
            build: "4.x"
            ansi_config:
              ceph_origin: repository
              ceph_repository: rhcs
              ceph_repository_type: cdn
              ceph_rhcs_version: 4
              osd_scenario: lvm
              osd_auto_discovery: false
              radosgw_frontend_ssl_certificate: "/etc/ceph/server.pem"
              radosgw_frontend_port: 443
              copy_admin_key: true
              dashboard_enabled: false
              rgw_multisite: true
              rgw_zone: US_WEST
              rgw_zonegroup: US
              rgw_realm: USA
              rgw_zonemaster: false
              rgw_zonesecondary: true
              rgw_zonegroupmaster: false
              rgw_zone_user: synchronization-user
              rgw_zone_user_display_name: "Synchronization User"
              system_access_key: 86nBoQOGpQgKxh4BLMyq
              system_secret_key: NTnkbmkMuzPjgwsBpJ6o
              rgw_multisite_proto: "https"
              rgw_pull_proto: https
              rgw_pull_port: 443
      desc: Deploying Ceph multisite RGW cluster using ceph-ansible
      module: test_ansible.py
      name: deploy ceph multisite cluster from cdn

  - test:
      clusters:
        ceph-rgw1:
          config:
            set-env: true
            script-name: user_create.py
            config-file-name: non_tenanted_user.yaml
            copy-user-info-to-site: ceph-rgw2
            timeout: 300
      desc: create non-tenanted user
      module: sanity_rgw_multisite.py
      name: create user

  - test:
      name: check-ceph-health
      module: exec.py
      config:
        commands:
         - "ceph -s"
         - "ceph versions"
         - "radosgw-admin sync status"
         - "radosgw-admin period get"
        sudo: True
      desc: check for ceph status and version

  # upgrade ceph cluster
  - test:
      name: ceph multisite upgrade
      module: test_ansible_upgrade.py
      clusters:
        ceph-rgw1:
          config:
            build: "4.x"
            ansi_config:
              ceph_origin: distro
              ceph_repository: rhcs
              ceph_rhcs_version: 4
              osd_scenario: lvm
              osd_auto_discovery: false
              copy_admin_key: true
              radosgw_frontend_ssl_certificate: "/etc/ceph/server.pem"
              radosgw_frontend_port: 443
              dashboard_enabled: false
              rgw_multisite: true
              rgw_zone: US_EAST
              rgw_zonegroup: US
              rgw_realm: USA
              rgw_zonemaster: true
              rgw_zonesecondary: false
              rgw_zonegroupmaster: true
              rgw_zone_user: synchronization-user
              rgw_zone_user_display_name: "Synchronization User"
              rgw_multisite_proto: "https"
              system_access_key: 86nBoQOGpQgKxh4BLMyq
              system_secret_key: NTnkbmkMuzPjgwsBpJ6o
              upgrade_ceph_packages: true
        ceph-rgw2:
          config:
            build: "4.x"
            ansi_config:
              ceph_origin: distro
              ceph_repository: rhcs
              ceph_rhcs_version: 4
              osd_scenario: lvm
              osd_auto_discovery: false
              copy_admin_key: true
              radosgw_frontend_ssl_certificate: "/etc/ceph/server.pem"
              radosgw_frontend_port: 443
              dashboard_enabled: false
              rgw_multisite: true
              rgw_zone: US_WEST
              rgw_zonegroup: US
              rgw_realm: USA
              rgw_zonemaster: false
              rgw_zonesecondary: true
              rgw_zonegroupmaster: false
              rgw_zone_user: synchronization-user
              rgw_zone_user_display_name: "Synchronization User"
              system_access_key: 86nBoQOGpQgKxh4BLMyq
              system_secret_key: NTnkbmkMuzPjgwsBpJ6o
              rgw_multisite_proto: "https"
              rgw_pullhost: "{node_ip:ceph-rgw1#node5}"
              rgw_pull_proto: https
              rgw_pull_port: 443
              upgrade_ceph_packages: true
      desc: Upgrading the clusters to the specified build.
      abort-on-fail: true
      polarion-id: CEPH-83574658

  - test:
      name: check-ceph-health
      module: exec.py
      config:
        commands:
         - "ceph -s"
         - "ceph versions"
         - "radosgw-admin period get"
        sudo: True
      desc: check for ceph status and version

